import streamlit as st
import google.generativeai as genai

# ---------------- PAGE CONFIG ----------------
st.set_page_config(page_title="NJ Tech AI", page_icon="ЁЯУ▒", layout="centered")

# ---------------- HEADER ----------------
st.title("ЁЯУ▒ NJ Tech Assistant")
st.caption("ЁЯЪА Powered by Gemini (Auto-Switch Mode)")

# ---------------- API KEY CHECK ----------------
# рокрпЖропро░ро┐ро▓рпН роХрпБро┤рокрпНрокроорпН ро╡рпЗрогрпНроЯро╛роорпН, роЗро░рогрпНроЯрпИропрпБроорпН родрпЗроЯрпБро╡рпЛроорпН
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
elif "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    st.error("тЭМ API Key Missing! Please add GOOGLE_API_KEY in Secrets.")
    st.stop()

# ---------------- CONFIGURE ----------------
# 'transport=rest' роорпБроХрпНроХро┐ропроорпН (Server Busy ро╡ро░ро╛рооро▓рпН роЗро░рпБроХрпНроХ)
genai.configure(api_key=api_key, transport="rest")

# ---------------- SMART MODEL SELECTOR (The Fix) ----------------
# роЗродрпБродро╛ройрпН роорпБроХрпНроХро┐ропроорпН! родро╛ройро╛роХро╡рпЗ ро╡рпЗро▓рпИ роЪрпЖропрпНропрпБроорпН рооро╛роЯро▓рпИродрпН родрпЗроЯрпБроорпН.
def get_working_model():
    model_list = ["gemini-1.5-flash", "gemini-pro", "gemini-1.0-pro"]
    for model_name in model_list:
        try:
            model = genai.GenerativeModel(model_name)
            # роЪрпБроорпНрооро╛ роТро░рпБ роЯрпЖро╕рпНроЯрпН роорпЖроЪрпЗроЬрпН роЕройрпБрокрпНрокро┐ рокро╛ро░рпНрокрпНрокрпЛроорпН
            model.generate_content("Hi")
            return model # ро╡рпЗро▓рпИ роЪрпЖропрпНродро╛ро▓рпН роЗродрпИропрпЗ роОроЯрпБрокрпНрокрпЛроорпН
        except:
            continue # ро╡рпЗро▓рпИ роЪрпЖропрпНропро▓ройро╛ роЕроЯрпБродрпНрод рооро╛роЯро▓рпН
    return None

# рооро╛роЯро▓рпИродрпН родрпЗро░рпНроирпНродрпЖроЯрпБрокрпНрокрпЛроорпН
if "model" not in st.session_state:
    with st.spinner("Connecting to Google..."):
        st.session_state.model = get_working_model()

if st.session_state.model is None:
    st.error("тЪая╕П роОроирпНрод рооро╛роЯро▓рпБроорпН ро╡рпЗро▓рпИ роЪрпЖропрпНропро╡ро┐ро▓рпНро▓рпИ. родропро╡рпБроЪрпЖропрпНродрпБ 'New Project' роХрпА роОроЯрпБроХрпНроХро╡рпБроорпН.")
    st.stop()

# ---------------- CHAT HISTORY ----------------
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "user", "content": "You are NJ Bot for NJ Tech. Speak in Tanglish."},
        {"role": "assistant", "content": "Vanakkam! ЁЯЩП Naan NJ Bot. Enna help venum?"}
    ]

# ---------------- DISPLAY CHAT ----------------
for msg in st.session_state.messages[1:]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ---------------- USER INPUT ----------------
if prompt := st.chat_input("Type here..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        try:
            # History conversion
            gemini_history = []
            for m in st.session_state.messages:
                role = "user" if m["role"] == "user" else "model"
                gemini_history.append({"role": role, "parts": [m["content"]]})
            
            response = st.session_state.model.generate_content(gemini_history)
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"Error: {e}")
