import streamlit as st
import google.generativeai as genai

# ---------------- CONFIG ----------------
st.set_page_config(page_title="NJ Tech AI", page_icon="ЁЯУ▒")
st.title("ЁЯУ▒ NJ Tech Assistant")
st.caption("ЁЯЪА Powered by Gemini (Auto-Switch)")

# ---------------- SECRETS CHECK ----------------
# API Key рокрпЖропро░рпИ 'GOOGLE_API_KEY' роЕро▓рпНро▓родрпБ 'GEMINI_API_KEY' роОрой роОродрпБ роЗро░рпБроирпНродро╛ро▓рпБроорпН роОроЯрпБродрпНродрпБроХрпНроХрпКро│рпНро│рпБроорпН
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
elif "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    st.error("тЭМ API Key Missing! Secrets-ро▓рпН роХрпАропрпИ роЪрпЖроХрпН роЪрпЖропрпНропро╡рпБроорпН.")
    st.stop()

genai.configure(api_key=api_key)

# ---------------- SMART MODEL LOAD ----------------
# роЗродрпБродро╛ройрпН роорпБроХрпНроХро┐ропроорпН! родро╛ройро╛роХро╡рпЗ ро╡рпЗро▓рпИ роЪрпЖропрпНропрпБроорпН рооро╛роЯро▓рпИродрпН родрпЗроЯрпБроорпН.
@st.cache_resource
def load_model():
    # ро╡ро░ро┐роЪрпИропро╛роХ роОро▓рпНро▓ро╛ рооро╛роЯро▓рпИропрпБроорпН роЯрпНро░рпИ рокрогрпНрогрпБро╡рпЛроорпН
    models_to_try = ["gemini-1.5-flash", "gemini-pro", "gemini-1.0-pro"]
    
    for m in models_to_try:
        try:
            test_model = genai.GenerativeModel(m)
            # роЪрпБроорпНрооро╛ роТро░рпБ 'Hi' роЪрпКро▓рпНро▓ро┐ роЯрпЖро╕рпНроЯрпН рокрогрпНрогрпБро╡рпЛроорпН
            test_model.generate_content("test")
            return test_model, m # ро╡рпЗро▓рпИ роЪрпЖропрпНродро╛ро▓рпН роЗродрпИропрпЗ роОроЯрпБрокрпНрокрпЛроорпН
        except:
            continue
    return None, None

model, model_name = load_model()

if model is None:
    st.error("тЪая╕П роОроирпНрод рооро╛роЯро▓рпБроорпН ро╡рпЗро▓рпИ роЪрпЖропрпНропро╡ро┐ро▓рпНро▓рпИ. родропро╡рпБроЪрпЖропрпНродрпБ 'New Project' роХрпАропрпИ Secrets-ро▓рпН роЪро░ро┐ропро╛роХ рокрпЛроЯро╡рпБроорпН.")
    st.stop()
else:
    # роОроирпНрод рооро╛роЯро▓рпН ро╡рпЗро▓рпИ роЪрпЖропрпНроХро┐ро▒родрпБ роОройрпНро▒рпБ роХро╛роЯрпНроЯрпБро╡рпЛроорпН
    st.success(f"тЬЕ Connected to: {model_name}")

# ---------------- CHAT LOGIC ----------------
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ро╡рогроХрпНроХроорпН! роиро╛ройрпН NJ Bot. роорпКрокрпИро▓рпН роЪро░рпНро╡рпАро╕рпН рокро▒рпНро▒ро┐ роХрпЗро│рпБроЩрпНроХ! ЁЯШК"}
    ]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("роХрпЗро│рпБроЩрпНроХ..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    
    with st.chat_message("assistant"):
        try:
            # History conversion
            history = [{"role": "user" if m["role"]=="user" else "model", "parts": [m["content"]]} for m in st.session_state.messages if m["role"] != "assistant"]
            response = model.generate_content(prompt)
            st.write(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"Error: {e}")
  
